{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-04 09:36:44,311 - Created a temporary directory at /tmp/tmppea7e2x4\n",
      "2025-04-04 09:36:44,315 - Writing /tmp/tmppea7e2x4/_remote_module_non_scriptable.py\n",
      "MONAI version: 1.0.1\n",
      "Numpy version: 1.23.4\n",
      "Pytorch version: 1.13.1\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 8271a193229fe4437026185e218d5b06f7c8ce69\n",
      "MONAI __file__: /home1/zc348/anaconda3/envs/dl-hmc_2301c/lib/python3.9/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 4.0.2\n",
      "scikit-image version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Pillow version: 9.2.0\n",
      "Tensorboard version: 2.11.0\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: 0.14.1\n",
      "tqdm version: 4.64.1\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.0\n",
      "pandas version: 1.4.3\n",
      "einops version: 0.6.0\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import monai\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from monai.transforms import \\\n",
    "    Compose, LoadImaged, AddChanneld, Orientationd, \\\n",
    "    Spacingd, \\\n",
    "    ToTensord,  \\\n",
    "    DataStatsd, \\\n",
    "    ToDeviced\n",
    "from monai.data import list_data_collate\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torchsummary import summary\n",
    "monai.config.print_config()\n",
    "import sys\n",
    "# sys.path.append(r'/data16/private/zc348/project/DL_HMC_attention/mCT/util/python')\n",
    "sys.path.append(r'/data16/private/zc348/project/DL_HMC_attention/util/python')\n",
    "import vicra_toolbox\n",
    "import nibabel; nibabel.imageglobals.logger.setLevel(40)\n",
    "# New transforms \n",
    "\n",
    "sys.path.append(r'../')\n",
    "\n",
    "torch.set_num_threads(4)\n",
    "from dlhmc.transforms import (\n",
    "    CreateImageStack,\n",
    "    ComputeRelativeMotion,\n",
    "    RandSamplePET,\n",
    "    ComputeRelativeMotiond,\n",
    "    CreateImageStackd,\n",
    "    RandSamplePETd,\n",
    ")\n",
    "\n",
    "from dlhmc.utils.data import (\n",
    "    concatenate_vicra,\n",
    "    split_dataset\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(UNet, self).__init__()\n",
    "        #Encode\n",
    "        self.conv_encode1 = self.contracting_block(in_channels=in_channel, out_channels=32)\n",
    "        self.conv_maxpool1 = torch.nn.MaxPool3d(kernel_size=2)\n",
    "        self.conv_encode2 = self.contracting_block(32, 64)\n",
    "        self.conv_maxpool2 = torch.nn.MaxPool3d(kernel_size=2)\n",
    "        self.conv_encode3 = self.contracting_block(64, 128)\n",
    "        self.conv_maxpool3 = torch.nn.MaxPool3d(kernel_size=2)\n",
    "\n",
    "\n",
    "    def contracting_block(self, in_channels, out_channels, kernel_size=3):\n",
    "        \"\"\"\n",
    "        This function creates one contracting block\n",
    "        \"\"\"\n",
    "        block = torch.nn.Sequential(\n",
    "            torch.nn.Conv3d(kernel_size=kernel_size, in_channels=in_channels, out_channels=out_channels, padding=1),\n",
    "            torch.nn.BatchNorm3d(out_channels),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv3d(kernel_size=kernel_size, in_channels=out_channels, out_channels=out_channels, padding=1),\n",
    "            torch.nn.BatchNorm3d(out_channels),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        return block\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encode\n",
    "        encode_block1 = self.conv_encode1(x)\n",
    "        encode_pool1 = self.conv_maxpool1(encode_block1)\n",
    "        encode_block2 = self.conv_encode2(encode_pool1)\n",
    "        encode_pool2 = self.conv_maxpool2(encode_block2)\n",
    "        \n",
    "        encode_block3 = self.conv_encode3(encode_pool2)\n",
    "        encode_pool3 = self.conv_maxpool3(encode_block3)\n",
    "\n",
    "\n",
    "        return encode_pool3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cross_attention(nn.Module):\n",
    "    def  __init__(self, all_channel=128, all_dim=4*4*4):\t\n",
    "\n",
    "        super(Cross_attention, self).__init__()\n",
    "        self.linear_e = nn.Linear(all_channel, all_channel,bias = False)\n",
    "        self.channel = all_channel\n",
    "        self.dim = all_dim\n",
    "        self.gate = nn.Conv3d(all_channel, 1, kernel_size  = 1, bias = False)\n",
    "        self.gate_s = nn.Sigmoid()\n",
    "        self.conv1 = nn.Conv3d(all_channel*1, all_channel, kernel_size=3, padding=1, bias = False)\n",
    "        self.conv2 = nn.Conv3d(all_channel*1, all_channel, kernel_size=3, padding=1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm3d(all_channel)\n",
    "        self.bn2 = nn.BatchNorm3d(all_channel)\n",
    "        self.prelu = nn.ReLU(inplace=True)\n",
    "        self.conv3d_7 = nn.Conv3d(in_channels=all_channel *2 , out_channels=all_channel, kernel_size=1, stride=(1, 1, 1), padding=0)\n",
    "        self.pathC_bn1 = nn.BatchNorm3d(all_channel*2)\n",
    "        self.conv3d_8 = nn.Conv3d(in_channels=all_channel, out_channels=all_channel//2, kernel_size=3, stride=(1, 1, 1), padding=1)\n",
    "        self.conv3d_9 = nn.Conv3d(in_channels=all_channel//2, out_channels=all_channel//8, kernel_size=3, stride=(1, 1, 1), padding=1)\n",
    "        self.pathC_bn2 = nn.BatchNorm3d(all_channel//8)\n",
    "\n",
    "        self.conva = nn.Conv3d(all_channel, all_channel, kernel_size=1, padding=0, bias = False)\n",
    "        self.convb = nn.Conv3d(all_channel, all_channel, kernel_size=1, padding=0, bias = False)\n",
    "    \n",
    "    \n",
    "\t\t\n",
    "    def forward(self, exemplar, query): \n",
    "        \n",
    "\t \n",
    "        fea_size = query.size()[2:]\t \n",
    "        \n",
    "        #### correlation matrix computation\n",
    "        exemplar_v =  self.convb(exemplar) \n",
    "        query_v =  self.convb(query) \n",
    "        exemplar_q =  self.conva(exemplar) \n",
    "        query_k =  self.conva(query) \n",
    "        exemplar_flat = exemplar_q.view(-1, self.channel, self.dim) #N,C,H*W\n",
    "        query_flat = query_k.view(-1, self.channel, self.dim)\n",
    "        exemplar_t = torch.transpose(exemplar_flat,1,2).contiguous()  #batch size x dim x num\n",
    "        A = torch.bmm(exemplar_t, query_flat)\n",
    "        A = F.softmax(A, dim = 1) \n",
    "        B = F.softmax(torch.transpose(A,1,2),dim=1)\n",
    "        query_att = torch.bmm(exemplar_v.view(-1, self.channel, self.dim) , A).contiguous() \n",
    "        exemplar_att = torch.bmm(query_v.view(-1, self.channel, self.dim), B).contiguous()\n",
    "        #####self-gate mechanism\n",
    "        input1_att = exemplar_att.view(-1, self.channel, fea_size[0], fea_size[1], fea_size[2])  \n",
    "        input2_att = query_att.view(-1, self.channel, fea_size[0], fea_size[1], fea_size[2])\n",
    "        input1_mask = self.gate(input1_att)\n",
    "        input2_mask = self.gate(input2_att)\n",
    "        input1_mask = self.gate_s(input1_mask)\n",
    "        input2_mask = self.gate_s(input2_mask)\n",
    "        input1_att = input1_att * input1_mask\n",
    "        input2_att = input2_att * input2_mask\n",
    "        input1_att = input1_att +  exemplar_v\n",
    "        input2_att = input2_att + query_v\n",
    "        ######Deep norm and fusion\n",
    "        input1_att  = self.conv1(input1_att )\n",
    "        input2_att  = self.conv2(input2_att ) \n",
    "        input1_att  = self.bn1(input1_att )\n",
    "        input2_att  = self.bn2(input2_att )\n",
    "        input1_att  = self.prelu(input1_att )\n",
    "        input2_att  = self.prelu(input2_att )\n",
    "\n",
    "        conv_input = torch.cat((input1_att, input2_att), 1)\n",
    "        x = self.pathC_bn1(conv_input)\n",
    "        x = self.conv3d_7(x)\n",
    "        x = self.prelu(x)\n",
    "        x = self.conv3d_8(x)\n",
    "        x = self.prelu(x)\n",
    "        x = self.conv3d_9(x)\n",
    "        x = self.pathC_bn2(x)\n",
    "\n",
    "        return x.view(x.size()[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cross_att_dataloader(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, dropout=0.3,img_size=32):\n",
    "        super().__init__()\n",
    "        \n",
    "             \n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.feature_extractor = UNet(1,1)\n",
    "\n",
    "        self.coattention = Cross_attention()\n",
    "\n",
    "\n",
    "        self.regression_layers = torch.nn.Sequential(\n",
    "\n",
    "            torch.nn.Linear(1024, 128),\n",
    "            torch.nn.Linear(128, 16),\n",
    "            torch.nn.Linear(16, 6),\n",
    "        )\n",
    "        self.loss_function = torch.nn.MSELoss()\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "\n",
    "        y1 = self.feature_extractor(x1)\n",
    "        y2 = self.feature_extractor(x2)\n",
    "        y = self.coattention(y1,y2)\n",
    "        y = self.regression_layers(y)\n",
    "        return y\n",
    "    \n",
    "    \n",
    "    \n",
    "    def prepare_data(self):\n",
    "        # set deterministic training for reproducibility\n",
    "        monai.utils.misc.set_determinism(seed=42)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x1 = batch[\"ThreeD_Cloud_ref\"]\n",
    "        x2 = batch[\"ThreeD_Cloud_mov\"]\n",
    "        ref_time = batch['ScanStart_ref']\n",
    "        mov_time = batch['ScanStart_mov']\n",
    "        # x_t = torch.stack([ref_time, mov_time], dim=1)\n",
    "        gt_reg = batch[\"VICRA_rel\"].float()\n",
    "        y = self.forward(x1,x2)\n",
    "       \n",
    "        target_six = matrix_transformation(gt_reg)\n",
    "        loss = self.loss_function(y, target_six)   \n",
    "\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "        \n",
    "    def training_epoch_end(self, outputs):\n",
    "        # Calculate the average loss\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        # Logging at the end of every epoch\n",
    "        self.logger.experiment.add_scalar('Train/Loss', avg_loss, self.current_epoch)\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x1 = batch[\"ThreeD_Cloud_ref\"]\n",
    "        x2 = batch[\"ThreeD_Cloud_mov\"]\n",
    "        ref_time = batch['ScanStart_ref']\n",
    "        mov_time = batch['ScanStart_mov']\n",
    "        x_t = torch.stack([ref_time, mov_time], dim=1)\n",
    "        gt_reg = batch[\"VICRA_rel\"].float()\n",
    "        y = self.forward(x1,x2)\n",
    "        target_six = matrix_transformation(gt_reg)\n",
    "        loss = self.loss_function(y, target_six)   \n",
    "\n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # Calculate the average loss\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        # Logging at the end of every epoch\n",
    "        self.logger.experiment.add_scalar('Val/Loss', avg_loss, self.current_epoch)\n",
    "\n",
    "        # Log the value for model checkpoint saving\n",
    "        self.log('val_loss', avg_loss.item()) #added .item(), otherwise validation wouldn't work \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        total_params = list(self.feature_extractor.parameters()) + list(self.regression_layers.parameters()) + list(self.coattention.parameters())\n",
    "        opt = torch.optim.Adam(total_params, lr=5e-4)\n",
    "        scheduler = {'scheduler': torch.optim.lr_scheduler.StepLR(optimizer=opt, step_size=200, gamma=0.98),\n",
    "                     'name': 'Learning Rate'}\n",
    "        return [opt], [scheduler]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_toolbox import build_df_results, show_df_loss, build_df_results_12, plot_vicra_network, plot_diff_vicra_network, save_synthetic_vicra, print_loss,plot_networks_comparison\n",
    "from dataset_summary_toolbox import compute_delta_T \n",
    "from data_prep_toolbox import delta_T_magnitude, Relative_motion_A_to_B_12, build_legal_dataset, deal_dataframe, clean_df\n",
    "from sampling_toolbox import data_split_sample, add_T_deltaT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set=['PF605', 'JB538', 'AF120', 'JG369', 'SY636',\n",
    "'EC950', 'NM937', 'AS469', 'CH568', 'JO308',\n",
    "'CJ509', 'SY869', 'BB688', 'HR322', 'DS636',\n",
    " 'JR684', 'JM100', 'SM968', 'TM628', 'MC181']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead.\n"
     ]
    }
   ],
   "source": [
    "summaries_test, delta_T_all_test=compute_delta_T(['FDG'], test_set,data_type='real')\n",
    "df_test=[]\n",
    "predictions=[]\n",
    "df_input_diff_all=[]\n",
    "\n",
    "for i in range(len(test_set)):\n",
    "    df_test.append(deal_dataframe(summaries_test[i]))\n",
    "\n",
    "\n",
    "KEYS = ['ThreeD_Cloud_ref','ThreeD_Cloud_mov'] \n",
    "\n",
    "train_transforms = Compose([\n",
    "    LoadImaged(keys=KEYS, reader='NibabelReader', as_closest_canonical=False),\n",
    "    AddChanneld(keys=KEYS), \n",
    "    Orientationd(keys=KEYS, axcodes='RAS'),\n",
    "    ToTensord(keys=KEYS)    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cross_att_dataloader(\n",
       "  (feature_extractor): UNet(\n",
       "    (conv_encode1): Sequential(\n",
       "      (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (4): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (conv_maxpool1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv_encode2): Sequential(\n",
       "      (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (4): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (conv_maxpool2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv_encode3): Sequential(\n",
       "      (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (4): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (conv_maxpool3): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (coattention): Cross_attention(\n",
       "    (linear_e): Linear(in_features=128, out_features=128, bias=False)\n",
       "    (gate): Conv3d(128, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "    (gate_s): Sigmoid()\n",
       "    (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (prelu): ReLU(inplace=True)\n",
       "    (conv3d_7): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (pathC_bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3d_8): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (conv3d_9): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (pathC_bn2): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conva): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "    (convb): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "  )\n",
       "  (regression_layers): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
       "    (1): Linear(in_features=128, out_features=16, bias=True)\n",
       "    (2): Linear(in_features=16, out_features=6, bias=True)\n",
       "  )\n",
       "  (loss_function): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "saved_model_path = '/data16/private/zc348/project/Best_FDG.ckpt'\n",
    "loaded_model = cross_att_dataloader().load_from_checkpoint(saved_model_path)\n",
    "loaded_model.eval()\n",
    "loaded_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:18<00:00, 12.06it/s]\n",
      "100%|██████████| 225/225 [00:24<00:00,  9.14it/s]\n",
      "100%|██████████| 225/225 [00:18<00:00, 12.13it/s]\n",
      "100%|██████████| 225/225 [00:17<00:00, 13.20it/s]\n",
      "100%|██████████| 225/225 [00:15<00:00, 14.15it/s]\n",
      "100%|██████████| 225/225 [00:19<00:00, 11.36it/s]\n",
      "100%|██████████| 225/225 [00:16<00:00, 13.25it/s]\n",
      "100%|██████████| 225/225 [00:15<00:00, 14.74it/s]\n",
      "100%|██████████| 225/225 [00:15<00:00, 14.71it/s]\n",
      "100%|██████████| 225/225 [00:15<00:00, 14.53it/s]\n",
      "100%|██████████| 225/225 [00:17<00:00, 13.00it/s]\n",
      "100%|██████████| 225/225 [00:16<00:00, 13.94it/s]\n",
      "100%|██████████| 225/225 [00:18<00:00, 11.98it/s]\n",
      "100%|██████████| 225/225 [00:17<00:00, 12.99it/s]\n",
      "100%|██████████| 225/225 [00:15<00:00, 14.12it/s]\n",
      "100%|██████████| 225/225 [00:18<00:00, 12.26it/s]\n",
      "100%|██████████| 225/225 [00:17<00:00, 12.73it/s]\n",
      "100%|██████████| 225/225 [00:17<00:00, 12.71it/s]\n",
      "100%|██████████| 225/225 [00:16<00:00, 13.51it/s]\n",
      "100%|██████████| 225/225 [00:17<00:00, 12.74it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "df_results_all=[]\n",
    "y_list_all=[]\n",
    "df_input_diff_all=[]\n",
    "prediction_list = list()\n",
    "times = torch.zeros((1800*len(test_set),1)) \n",
    "# torch.cuda.synchronize()\n",
    "# starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "idx=0\n",
    "\n",
    "for j in range(len(test_set)):\n",
    "\n",
    "    df = df_test[j]\n",
    "\n",
    "    #fixed reference time\n",
    "    df_input_diff = vicra_toolbox.build_netinput_fixed_reference(df).reset_index()\n",
    "    pairs=[]\n",
    "    for i in range(len(df_input_diff)):\n",
    "        pairs.append(np.array([df_input_diff['ScanStart_ref'][i], df_input_diff['ScanStart_mov'][i]]))\n",
    "    df_input_diff['pairs']=pairs\n",
    "    \n",
    "    df_input_diff_all.append(df_input_diff)\n",
    "\n",
    "    ##building testing dataloader\n",
    "    test_dict = df_input_diff.to_dict('records')\n",
    "\n",
    "    for i in range(len(test_dict)):\n",
    "        x = test_dict[i]['ThreeD_Cloud_ref'].find('nii')\n",
    "        fn_cloud1 = test_dict[i]['ThreeD_Cloud_ref'][0:x] + 'nii_monai_resize'\n",
    "        x = x+3\n",
    "        y = test_dict[i]['ThreeD_Cloud_ref'].find('3dcld')\n",
    "        fn_cloud2 =  test_dict[i]['ThreeD_Cloud_ref'][x:y] + '3dcld_monai_rz.nii'\n",
    "        test_dict[i]['ThreeD_Cloud_ref'] = fn_cloud1 + fn_cloud2\n",
    "\n",
    "        x = test_dict[i]['ThreeD_Cloud_mov'].find('nii')\n",
    "        fn_cloud1 = test_dict[i]['ThreeD_Cloud_mov'][0:x] + 'nii_monai_resize'\n",
    "        x = x+3\n",
    "        y = test_dict[i]['ThreeD_Cloud_mov'].find('3dcld')\n",
    "        fn_cloud2 =  test_dict[i]['ThreeD_Cloud_mov'][x:y] + '3dcld_monai_rz.nii'\n",
    "        test_dict[i]['ThreeD_Cloud_mov'] = fn_cloud1 + fn_cloud2\n",
    "\n",
    "    # Create the Dataset\n",
    "#     ds_test = monai.data.CacheDataset(data=test_dict, transform=train_transforms)\n",
    "    ds_test = monai.data.Dataset(data=test_dict, transform=train_transforms)\n",
    "    #ds_tr = monai.data.SmartCacheDataset(data=tr_dict,transform=train_transforms,replace_rate=1,cache_num=64,shuffle=True)\n",
    "    # Create the DataLoader\n",
    "    test_loader = monai.data.DataLoader(ds_test, batch_size=8, num_workers=2, collate_fn=list_data_collate)\n",
    "    \n",
    "    #calculate loss function and network output\n",
    "    # saved_model_path = os.path.join(MODEL_PATH,'PETRegNet-epoch=3130-val_loss=0.454.ckpt')\n",
    "    # loaded_model = PETRegNet.load_from_checkpoint(saved_model_path)\n",
    "\n",
    "\n",
    "    loss = 0\n",
    "    loss_list = list()\n",
    "    time_list = list()\n",
    "    \n",
    "    y_list = list()\n",
    "    loss1 = []\n",
    "    \n",
    "    pp = 0\n",
    "    for test_data in tqdm(test_loader):\n",
    "        x1 = test_data['ThreeD_Cloud_ref'].to(device)\n",
    "        x2 = test_data['ThreeD_Cloud_mov'].to(device)\n",
    "        x_t = test_data['pairs'].to(device)\n",
    "        time = test_data['delta_t']\n",
    "        ref_time = test_data['ScanStart_ref']\n",
    "        mov_time = test_data['ScanStart_mov']\n",
    "        x_t = torch.stack([ref_time, mov_time], dim=1).to(device)\n",
    "        y = test_data['T'].cpu().numpy()\n",
    "        # starter.record()\n",
    "        y_test = loaded_model(x1, x2).detach().cpu().numpy()\n",
    "        torch.cuda.synchronize() \n",
    "        loss = y-y_test\n",
    "        l = len(loss)\n",
    "        for j in range(l):\n",
    "            loss1=sum(np.square(loss[j]))/len(loss[j])\n",
    "            loss_list.append(loss1)\n",
    "            time_list.append(time.numpy()[j])\n",
    "            prediction_list.append(y_test[j])\n",
    "            y_list.append(y[j])\n",
    "            pp+=1\n",
    "            # print(loss1)\n",
    "        del test_data\n",
    "        idx= idx+1\n",
    "        \n",
    "    \n",
    "    df_results = pd.DataFrame()\n",
    "    y_list_all.append(y_list)\n",
    "    \n",
    "    df_results['Time'] = time_list\n",
    "    df_results['Loss'] = loss_list\n",
    "    df_results_all.append(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "class RMSE(nn.Module):\n",
    "    def __init__(self, prediction,gt,class_num):\n",
    "        np.random.seed(42)  # \n",
    "        num_cases = class_num\n",
    "        num_results_per_case = 1800\n",
    "        self.data = np.stack(prediction)\n",
    "        self.data = self.data.reshape(num_cases,num_results_per_case,1,6)\n",
    "        self.gt = np.stack(gt)\n",
    "        self.gt = self.gt.reshape(num_cases,num_results_per_case,1,6)\n",
    "        self.translation_rmses = []\n",
    "        self.rotation_rmses = []\n",
    "        self.total_rmses = []\n",
    "\n",
    "    def calculate_rmse(self, true, pred):\n",
    "        return np.sqrt(mean_squared_error(true, pred))\n",
    "    \n",
    "    def calculate_statistics(self, data):\n",
    "        mean = np.mean(data)\n",
    "        variance = np.var(data)\n",
    "        median = np.median(data)\n",
    "        q1 = np.percentile(data, 25)\n",
    "        q3 = np.percentile(data, 75)\n",
    "        iqr = q3 - q1\n",
    "        return mean, variance, median, iqr\n",
    "    \n",
    "    def forward(self):\n",
    "        for case, case_gt in zip(self.data,self.gt):\n",
    "            # obtain translation & rotation\n",
    "            translations = case[:, :, :3]  # translation\n",
    "            rotations = case[:, :, 3:]    # rotation\n",
    "\n",
    "            translations_gt = case_gt[:, :, :3]  # translation\n",
    "            rotations_gt = case_gt[:, :, 3:]    # rotation\n",
    "            # each case translation and rotation RMSE\n",
    "            translation_rmse = self.calculate_rmse(translations.flatten(), translations_gt.flatten())\n",
    "            rotation_rmse = self.calculate_rmse(rotations.flatten(), rotations_gt.flatten())\n",
    "            total_rmse = self.calculate_rmse(case.flatten(), case_gt.flatten())\n",
    "\n",
    "            self.translation_rmses.append(translation_rmse)\n",
    "            self.rotation_rmses.append(rotation_rmse)\n",
    "            self.total_rmses.append(total_rmse)\n",
    "\n",
    "\n",
    "\n",
    "        # \n",
    "        translation_mean, translation_var, translation_median, translation_iqr = self.calculate_statistics(self.translation_rmses)\n",
    "        rotation_mean, rotation_var, rotation_median, rotation_iqr = self.calculate_statistics(self.rotation_rmses)\n",
    "        total_mean, total_var, total_median, total_iqr = self.calculate_statistics(self.total_rmses)\n",
    "        \n",
    "        # print\n",
    "        print(\"Translation RMSE:\")\n",
    "        print(f\"Mean: {translation_mean}, SD: {translation_var}, Median: {translation_median}, IQR: {translation_iqr}\")\n",
    "\n",
    "        print(\"\\nRotation RMSE:\")\n",
    "        print(f\"Mean: {rotation_mean}, SD: {rotation_var}, Median: {rotation_median}, IQR: {rotation_iqr}\")\n",
    "\n",
    "        print(\"\\nTotal RMSE:\")\n",
    "        print(f\"Mean: {total_mean}, SD: {total_var}, Median: {total_median}, IQR: {total_iqr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation RMSE:\n",
      "Mean: 1.2654570927698043, SD: 0.4624681273977167, Median: 1.1494540428074, IQR: 0.6367913300291387\n",
      "\n",
      "Rotation RMSE:\n",
      "Mean: 1.1643550047873894, SD: 1.2026572332472591, Median: 0.8887497633560273, IQR: 0.3429450120230557\n",
      "\n",
      "Total RMSE:\n",
      "Mean: 1.2457516438031546, SD: 0.7592176376916496, Median: 1.043129245769346, IQR: 0.4542637601312354\n"
     ]
    }
   ],
   "source": [
    "CRMSE_cross = RMSE(np.stack(y_list_all),np.stack(prediction_list),len(test_set))\n",
    "CRMSE_cross.forward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-hmc_2301c",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
